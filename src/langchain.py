"""langchain.py

í•œêµ­ í˜•ë²•Â·í˜•ì‚¬ì†Œì†¡ë²• PDF â†’ í…ìŠ¤íŠ¸ ë¶„í•  â†’ OpenAI ì„ë² ë”©(text-embedding-small) â†’ Chroma ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ê¸°ì¡´ build_kb.py ë¥¼ ëŒ€ì²´í•œë‹¤. ì‹¤í–‰ í›„
    data/processed/chroma/  ì•„ë˜ì— ë²¡í„° ì¸ë±ìŠ¤ê°€ ì €ì¥ëœë‹¤.
"""
from pathlib import Path

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma


DOC_DIR = Path("documents")
PDF_FILES = [
    DOC_DIR / "í˜•ë²•(ë²•ë¥ ).pdf",
    DOC_DIR / "í˜•ì‚¬ì†Œì†¡ë²•(ë²•ë¥ ).pdf",
]
PERSIST_DIR = Path("data/processed/chroma")
PERSIST_DIR.mkdir(parents=True, exist_ok=True)

# LangChain ì»´í¬ë„ŒíŠ¸
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1500,
    chunk_overlap=100,
    separators=["\n\n", "\n", " "]
)
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")



def load_documents() -> list:
    """PDF íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ í…ìŠ¤íŠ¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    documents = []
    for pdf_path in PDF_FILES:
        if not pdf_path.exists():
            raise FileNotFoundError(f"âŒ {pdf_path} ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. PDF ë¥¼ documents/ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")

        loader = PyPDFLoader(str(pdf_path))
        pages = loader.load()  # ê° í˜ì´ì§€ê°€ Document ê°ì²´
        for page in pages:
            # í˜ì´ì§€ ë‹¨ìœ„ â†’ splitter ë¡œ ì¶”ê°€ ë¶„í• 
            documents.extend(splitter.split_documents([page]))
    return documents



def build_db():
    """Chroma ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• í›„ retriever ë°˜í™˜"""
    docs = load_documents()
    print(f"ğŸ“„ ë¬¸ì„œ ì²­í¬ ìˆ˜: {len(docs)}  / ì„ë² ë”© ìƒì„± ì¤‘ â€¦")

    vector_store = Chroma.from_documents(
        documents=docs,
        embedding=embeddings,
        collection_name="criminal_law",
        persist_directory=str(PERSIST_DIR)
    )
    vector_store.persist()
    print(f"âœ… Chroma ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ â†’ {PERSIST_DIR}")
    return vector_store.as_retriever(search_kwargs={"k": 3})


if __name__ == "__main__":
    build_db()
