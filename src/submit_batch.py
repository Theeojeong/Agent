# src/submit_batch.py
from openai import OpenAI
import time

client = OpenAI()                       # OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”

def create_and_wait(input_path: str = "batch_input.jsonl",
                    output_path: str = "batch_output.jsonl",
                    poll_sec: int = 60):
    """OpenAI Batch API ì œì¶œ í›„ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°, ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""

    # 1) ì…ë ¥ íŒŒì¼ ì—…ë¡œë“œ
    with open(input_path, "rb") as f:
        file_obj = client.files.create(file=f, purpose="batch")
    print("ğŸ“¤ Uploaded input file:", file_obj.id)

    # 2) ë°°ì¹˜ ì‘ì—… ìƒì„±
    batch = client.batches.create(
        input_file_id=file_obj.id,
        endpoint="/v1/chat/completions",
        completion_window="24h"
    )
    print("ğŸ†” Batch ID:", batch.id)

    # 3) í´ë§í•˜ì—¬ ìƒíƒœ í™•ì¸
    while True:
        status = client.batches.retrieve(batch.id).status
        print("âŒ› Current status:", status)
        if status in {"failed", "expired"}:
            raise RuntimeError(f"Batch ended with status: {status}")
        if status == "completed":
            break
        time.sleep(poll_sec)

    # 4) ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    file_id = client.batches.retrieve(batch.id).output_file_id
    content = client.files.content(file_id)
    with open(output_path, "wb") as f:
        for chunk in content.iter_bytes():
            f.write(chunk)
    print(f"âœ… Batch completed. Output saved to {output_path}")

if __name__ == "__main__":
    create_and_wait()
