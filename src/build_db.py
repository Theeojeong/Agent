from __future__ import annotations

from pathlib import Path

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

DOC_DIR = Path("documents")
PDF_FILES = [
    DOC_DIR / "í˜•ë²•(ë²•ë¥ ).pdf",
    DOC_DIR / "í˜•ì‚¬ì†Œì†¡ë²•(ë²•ë¥ ).pdf",
]
PERSIST_DIR = Path("data/processed/chroma")
PERSIST_DIR.mkdir(parents=True, exist_ok=True)

# LangChain
splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,
    chunk_overlap=100,
    separators=["\n\n", "\n", " "]
)
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")


def load_documents() -> list:
    """PDF íŒŒì¼ ë¡œë“œ -> í…ìŠ¤íŠ¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    documents = []
    for pdf_path in PDF_FILES:
        if not pdf_path.exists():
            raise FileNotFoundError(
                f"{pdf_path} ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            )

        loader = PyPDFLoader(str(pdf_path))
        pages = loader.load()  # ê° í˜ì´ì§€ê°€ Document ê°ì²´
        for page in pages:
            # í˜ì´ì§€ ë‹¨ìœ„ â†’ splitter ë¡œ ì¶”ê°€ ë¶„í• 
            documents.extend(splitter.split_documents([page]))
    return documents


def build_db():
    """Chroma ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• í›„ retriever ë°˜í™˜"""
    docs = load_documents()
    print(f"ğŸ“„ ë¬¸ì„œ ì²­í¬ ìˆ˜: {len(docs)}  / ì„ë² ë”© ìƒì„± ì¤‘ â€¦")

    vector_store = Chroma.from_documents(
        documents=docs,
        embedding=embeddings,
        collection_name="criminal_law",
        persist_directory=str(PERSIST_DIR),
    )
    print(f"Chroma ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ â†’ {PERSIST_DIR}")
    return vector_store.as_retriever(search_kwargs={"k": 3})


if __name__ == "__main__":
    build_db()
