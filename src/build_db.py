from __future__ import annotations
from pathlib import Path
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader  
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

DOC_DIR = Path("documents")
PDF_FILES = [
    DOC_DIR / "í˜•ë²•(ë²•ë¥ ).pdf",
    DOC_DIR / "í˜•ì‚¬ì†Œì†¡ë²•(ë²•ë¥ ).pdf",
]
PERSIST_DIR = Path("data/processed/chroma")
PERSIST_DIR.mkdir(parents=True, exist_ok=True)


splitter = RecursiveCharacterTextSplitter(
    chunk_size=600,
    chunk_overlap=120,
    separators=["\n\n", "\n", " "]
)

embedding_function = OpenAIEmbeddings(model="text-embedding-3-small")


def load_documents() -> list:
    """PDF íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ í…ìŠ¤íŠ¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    documents = []
    for pdf_path in PDF_FILES:
        if not pdf_path.exists():
            raise FileNotFoundError(f"âŒ {pdf_path} ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        loader = PyMuPDFLoader(str(pdf_path))
        pages = loader.load()
        for page in pages:
            documents.extend(splitter.split_documents([page]))
    return documents


def main():
    """Chroma ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• í›„ retriever ë°˜í™˜"""
    docs = load_documents()
    print(f"ğŸ“„ ë¬¸ì„œ ì²­í¬ ìˆ˜: {len(docs)}  / ì„ë² ë”© ìƒì„± ì¤‘ â€¦")

    vector_store = Chroma.from_documents(
        documents=docs,
        embedding=embedding_function,
        collection_name="criminal_law",
        persist_directory=str(PERSIST_DIR),
    )
    vector_store.persist()
    print("âœ… Chroma ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ")

    retriever = vector_store.as_retriever(search_kwargs={"k": 3})
    return retriever


def get_retriever(k: int, search_type: str):
    vector_store = Chroma(
        persist_directory=str(PERSIST_DIR),
        embedding_function=embedding_function,
        collection_name="criminal_law",
    )
    search_kwargs = {"k": k}
    if search_type == "mmr":
        # MMRì¼ ë•Œë§Œ ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©
        search_kwargs.update({"fetch_k": max(20, k * 5), "lambda_mult": 0.7})
    return vector_store.as_retriever(search_type=search_type, search_kwargs=search_kwargs)


if __name__ == "__main__":
    main()
